name: "Production v48 (Highlander: Only 1 Active Bot)"

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

# üõë THIS IS THE FIX (Concurrency Group) üõë
# ‡§á‡§∏‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨: "Production Bot" ‡§®‡§æ‡§Æ ‡§ï‡§æ ‡§∏‡§ø‡§∞‡•ç‡§´ 1 ‡§∞‡§®‡§∞ ‡§ö‡§≤ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§
# ‡§ú‡•à‡§∏‡•á ‡§π‡•Ä ‡§®‡§Ø‡§æ ‡§Ü‡§è‡§ó‡§æ, ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§µ‡§æ‡§≤‡§æ (cancel-in-progress: true) ‡§Æ‡§∞ ‡§ú‡§æ‡§è‡§ó‡§æ‡•§
concurrency:
  group: "production-bot-v1"
  cancel-in-progress: true

jobs:
  run-highlander:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      # ==================================================================
      # 1. OPTIMIZATION
      # ==================================================================
      - name: üõ†Ô∏è Optimization
        run: |
          sudo fallocate -l 2G /swapfile && sudo chmod 600 /swapfile
          sudo mkswap /swapfile && sudo swapon /swapfile
          sudo sysctl -w net.core.default_qdisc=fq
          sudo sysctl -w net.ipv4.tcp_congestion_control=bbr
          sudo apt-get update && sudo apt-get install -y sqlite3
          echo "‚úÖ Server Tuned"

      # ==================================================================
      # 2. TUNNELING
      # ==================================================================
      - name: üöá Start Static Tunnel
        run: |
          curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null
          echo "deb https://ngrok-agent.s3.amazonaws.com buster main" | sudo tee /etc/apt/sources.list.d/ngrok.list
          sudo apt update && sudo apt install ngrok
          ngrok config add-authtoken ${{ secrets.NGROK_TOKEN }}
          ngrok http --domain=${{ secrets.NGROK_DOMAIN }} 80 > ngrok.log &
          sleep 5
          echo "‚úÖ Tunnel Live"

      # ==================================================================
      # 3. SAFE SNAPSHOT SYNC
      # ==================================================================
      - name: üíæ Setup Data & Safe Sync
        env:
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE }}
        run: |
          npm install @supabase/supabase-js
          mkdir -p n8n_data/nodes
          
          # SMART SYNC (Snapshot Logic)
          cat << 'EOF' > smart_sync.js
          const { createClient } = require('@supabase/supabase-js');
          const fs = require('fs');
          const crypto = require('crypto');
          const { execSync } = require('child_process');
          
          const liveDb = 'n8n_data/database.sqlite';
          const safeDb = 'n8n_data/database_snapshot.sqlite';
          const supabase = createClient('https://ymatdzammnejrmmiyygg.supabase.co', process.env.SUPABASE_KEY);
          
          function getFileHash(p) { if (!fs.existsSync(p)) return null; return crypto.createHash('md5').update(fs.readFileSync(p)).digest('hex'); }
          let lastHash = null;

          async function run(mode) {
            try {
                if(mode==='down') {
                  console.log("üì• Downloading Backup...");
                  const { data, error } = await supabase.storage.from('bot-storage').download('database.sqlite');
                  if(!error) {
                     fs.writeFileSync(liveDb, Buffer.from(await data.arrayBuffer()));
                     lastHash = getFileHash(liveDb);
                     console.log(`‚úÖ Restored (Hash: ${lastHash})`);
                  } else { console.log("‚ö†Ô∏è Fresh Start"); }
                } else {
                  if(!fs.existsSync(liveDb)) return;
                  try {
                    if (fs.existsSync(safeDb)) fs.unlinkSync(safeDb);
                    execSync(`sqlite3 ${liveDb} ".backup '${safeDb}'"`);
                  } catch (err) { fs.copyFileSync(liveDb, safeDb); }

                  const currentHash = getFileHash(safeDb);
                  if (currentHash === lastHash) { console.log("üí§ No Changes."); return; }
                  
                  console.log(`üì§ Uploading Snapshot...`);
                  const { error } = await supabase.storage.from('bot-storage').upload('database.sqlite', fs.readFileSync(safeDb), { upsert: true });
                  if(!error) { console.log("‚úÖ Saved"); lastHash = currentHash; }
                }
            } catch (e) { console.error("Sync Error:", e.message); }
          }
          run(process.argv[2]);
          EOF
          
          node smart_sync.js down
          
          echo "üì¶ Installing Nodes..."
          cd n8n_data/nodes && npm init -y && npm install n8n-nodes-datastore n8n-nodes-run-node-with-credentials-x n8n-nodes-tesseractjs && cd ../..
          echo "üîì Unlocking Permissions..."
          sudo chmod -R 777 n8n_data

      # ==================================================================
      # 4. LAUNCH SERVICES
      # ==================================================================
      - name: üöÄ Launch Services
        run: |
          docker network create bot-net

          mkdir ai
          cat << 'EOF' > ai/ai_server.py
          import g4f, flask; from flask import request, jsonify; app = flask.Flask(__name__)
          @app.route('/chat', methods=['POST'])
          def chat():
              try: return jsonify({"response": g4f.ChatCompletion.create(model=g4f.models.gpt_4, messages=[{"role":"user","content":request.json.get('message')}])})
              except Exception as e: return jsonify({"error":str(e)}),500
          if __name__ == '__main__': app.run(host='0.0.0.0', port=5000)
          EOF
          docker run -d --name ai-server --network bot-net -v $(pwd)/ai:/app -w /app python:3.9-slim sh -c "pip install flask g4f curl_cffi && python ai_server.py"

          docker run -d --name n8n --network bot-net \
            -v $(pwd)/n8n_data:/home/node/.n8n \
            -e N8N_ENCRYPTION_KEY="${{ secrets.N8N_ENCRYPTION_KEY }}" \
            -e N8N_SECURE_COOKIE=false \
            -e WEBHOOK_URL="https://${{ secrets.NGROK_DOMAIN }}" \
            n8nio/n8n

          mkdir whatsapp
          echo '{"name":"wa-bot","dependencies":{"@whiskeysockets/baileys":"6.6.0","axios":"^1.6.0","express":"^4.18.2","mongoose":"^8.0.0","pino":"^8.16.1","qrcode":"^1.5.3","node-cache":"^5.1.2"}}' > whatsapp/package.json
          
          cat << 'EOF' > whatsapp/index.js
          const { default: makeWASocket, DisconnectReason, BufferJSON, useMultiFileAuthState, makeCacheableSignalKeyStore } = require('@whiskeysockets/baileys');
          const express = require('express'); const axios = require('axios'); const mongoose = require('mongoose'); const QRCode = require('qrcode'); const pino = require('pino');
          const app = express(); app.use(express.json());
          const PORT = 10000; const N8N_URL = "http://n8n:5678/webhook/whatsapp"; const MONGO_URL = process.env.MONGODB_URI;
          const COLLECTION_NAME = 'Auth_Final_v1'; 
          const authSchema = new mongoose.Schema({ _id: String, data: Object }); const AuthModel = mongoose.model(COLLECTION_NAME, authSchema);
          async function useMongoDB() {
              const writeData = async (data, id) => { try { await AuthModel.findOneAndUpdate({ _id: id }, { data: JSON.parse(JSON.stringify(data, BufferJSON.replacer)), _id: id }, { upsert: true }); } catch (err) {} };
              const readData = async (id) => { try { const doc = await AuthModel.findById(id); return doc ? JSON.parse(JSON.stringify(doc.data), BufferJSON.reviver) : null; } catch (err) { return null; } };
              const removeData = async (id) => { try { await AuthModel.findByIdAndDelete(id); } catch (err) {} };
              const creds = (await readData('creds')) || (await (require('@whiskeysockets/baileys').initAuthCreds)());
              return { state: { creds, keys: { get: async (t, i) => { const d = {}; await Promise.all(i.map(async id => { let v = await readData(`${t}-${id}`); if (t === 'app-state-sync-key' && v) v = require('@whiskeysockets/baileys/lib/Utils/auth-utils').proto.Message.AppStateSyncKeyData.fromObject(v); if (v) d[id] = v; })); return d; }, set: async (d) => { const t = []; for (const c in d) for (const i in d[c]) { const v = d[c][i], k = `${c}-${i}`; t.push(v ? writeData(v, k) : removeData(k)); } await Promise.all(t); } } }, saveCreds: () => writeData(creds, 'creds'), clear: async () => { await AuthModel.deleteMany({}); } };
          }
          let sock; let qrData = null;
          async function start() {
              try {
                  if(mongoose.connection.readyState === 0) await mongoose.connect(MONGO_URL);
                  const { state, saveCreds, clear } = await useMongoDB(); global.clear = clear;
                  sock = makeWASocket({ auth: { creds: state.creds, keys: makeCacheableSignalKeyStore(state.keys, pino({ level: "fatal" })) }, logger: pino({ level: 'silent' }), printQRInTerminal: false, browser: ["Shiksha AI", "Chrome", "1.0.0"], connectTimeoutMs: 60000 });
                  sock.ev.on('creds.update', saveCreds);
                  sock.ev.on('connection.update', async (u) => { const { connection, lastDisconnect, qr } = u; if(qr) qrData = qr; if(connection === 'open') { qrData = null; console.log("‚úÖ Connected"); } if(connection === 'close') { const code = lastDisconnect.error?.output?.statusCode; if(code === DisconnectReason.loggedOut) { await clear(); process.exit(1); } else { setTimeout(start, 3000); } } });
                  sock.ev.on('messages.upsert', async ({ messages }) => { const msg = messages[0]; if(!msg.message || msg.key.fromMe) return; try { const realNumber = (msg.key.participant || msg.key.remoteJid).split('@')[0]; await axios.post(N8N_URL, { from: realNumber, text: msg.message.conversation || msg.message.extendedTextMessage?.text, name: msg.pushName, full_json: msg }); } catch (e) {} });
              } catch (e) { setTimeout(start, 5000); }
          }
          app.post('/send', async (req, res) => { try { if (!sock) return res.status(503).json({ error: "Start" }); const { number, message } = req.body; const fullId = number.includes('@') ? number : `${number}@s.whatsapp.net`; await sock.sendMessage(fullId, { text: message }); res.json({ status: true }); } catch (e) { res.status(500).json({ error: e.message }); } });
          app.get('/qr', async (req, res) => { if(sock?.user && !qrData) return res.send('<h1>‚úÖ Connected</h1><a href="/reset">Reset</a>'); if(!qrData) return res.send('<h1>‚è≥ Generating...</h1>'); const url = await QRCode.toDataURL(qrData); res.send(`<div style="text-align:center"><h1>Scan QR</h1><img src="${url}" /><br/><a href="/reset">Reset DB</a></div>`); });
          app.get('/reset', async (req, res) => { if(global.clear) await global.clear(); res.send("<h1>Wiped. Restarting...</h1>"); process.exit(1); });
          app.listen(PORT, () => { console.log(`Bot on ${PORT}`); start(); });
          EOF
          
          docker run -d --name caddy --network bot-net -p 80:80 -v $(pwd)/Caddyfile:/etc/caddy/Caddyfile caddy:latest
          docker run -d --name wa-bot --network bot-net -v $(pwd)/whatsapp:/app -w /app -e MONGODB_URI="${{ secrets.MONGODB_URI }}" node:20-alpine sh -c "apk add --no-cache git && npm install && while true; do node index.js; echo 'Restarting...'; sleep 2; done"

      # ==================================================================
      # 5. THE HIGHLANDER LOGIC (Backup -> Trigger -> Die)
      # ==================================================================
      - name: ‚è±Ô∏è Run Relay Timer
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE }}
        run: |
          echo "‚úÖ System Live at https://${{ secrets.NGROK_DOMAIN }}"
          START_TIME=$(date +%s)
          TRIGGERED=false
          while true; do
             CURRENT_TIME=$(date +%s); ELAPSED=$((CURRENT_TIME - START_TIME))
             
             # Trigger Next Runner at 5h 50m (21000 sec)
             if [ $ELAPSED -ge 21000 ] && [ "$TRIGGERED" = false ]; then
                 echo "üíæ Performing FINAL BACKUP before Death..."
                 node smart_sync.js up
                 
                 echo "üî´ TRIGGERING NEW RUNNER..."
                 gh workflow run main.yml
                 
                 echo "üíÄ I will be killed by Concurrency in a moment..."
                 TRIGGERED=true
                 sleep 300 # Wait for the new runner to kill me
             fi

             if ! docker ps | grep -q n8n; then docker restart n8n; fi
             if ! docker ps | grep -q wa-bot; then docker restart wa-bot; fi
             
             node smart_sync.js up
             sleep 900
          done
